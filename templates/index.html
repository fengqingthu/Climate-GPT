<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Climate-GPT</title>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="stylesheet" href="{{ url_for('static', filename='styles/style.css') }}">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
</head>

<body>
  <!-- partial:index.partial.html -->
  <section class="msger">
    <header class="msger-header">
      <div class="msger-header-title">
        Climate-GPT
      </div>
    </header>

    <main class="msger-chat">
      <div class="msg left-msg">
        <div class="msg-img" style="background-image: url(/static/earth.png)"></div>

        <div class="msg-bubble">
          <div class="msg-info">
            <div class="msg-info-name">Climate-GPT</div>
            <!-- <div class="msg-info-time"></div> -->
          </div>
          <div class="msg-text">
          </div>
        </div>
      </div>

    </main>

    <form class="msger-inputarea">
      <input type="text" class="msger-input" id="textInput" placeholder="Enter your message...">
      <button type="submit" class="msger-send-btn">Send</button>
      <button type="button" class="msger-mic-btn" id="micBtn">Speak</button>
    </form>
  </section>
  <!-- partial -->
  <script src='https://use.fontawesome.com/releases/v5.0.13/js/all.js'></script>
  <script>

    const msgerForm = get(".msger-inputarea");
    const msgerInput = get(".msger-input");
    const msgerChat = get(".msger-chat");

    const BOT_IMG = "{{ url_for('static', filename='earth.png') }}";
    const PERSON_IMG = "{{ url_for('static', filename='user.png') }}";
    const BOT_NAME = "Climate-GPT";
    const PERSON_NAME = "You";

    const INITIALIZATION = "Hi, welcome to Climate-GPT. Send me a message to start chat " +
      "or click the Speak button to talk to me! \n\nI will generate an image accordingly if " +
      "your message starts with 'show me an image of ...'. " +
      "You can also send me a reddit thread url so that I can monitor for new comments and auto-reply.";
    revealText(INITIALIZATION, 20);

    msgerForm.addEventListener("submit", event => {
      event.preventDefault();

      const msgText = msgerInput.value;
      if (!msgText) return;

      appendMessage(PERSON_NAME, PERSON_IMG, "right", msgText);
      msgerInput.value = "";
      botResponse(msgText);
    });

    const micBtn = get(".msger-mic-btn");
    let isRecording = false;
    let mediaRecorder;

    micBtn.addEventListener("click", () => {
      if (!isRecording) {
        // Request access to the microphone
        navigator.mediaDevices.getUserMedia({ audio: true })
          .then((stream) => {
            mediaRecorder = new MediaRecorder(stream);
            const chunks = [];

            // Manually request data at regular intervals for browsers like Safari
            const requestDataInterval = setInterval(() => {
              mediaRecorder.requestData();
            }, 500);

            mediaRecorder.addEventListener("dataavailable", (event) => {
              chunks.push(event.data);
            });

            mediaRecorder.addEventListener("stop", () => {
              clearInterval(requestDataInterval);

              let blob = new Blob(chunks, { type: "audio/wav" });
              // downloadWebm(blob);
              botResponseAudioInput(blob);

              // Reset recording status and button text
              mediaRecorder = null;
              isRecording = false;
              micBtn.textContent = "Speak";
              micBtn.classList.remove("recording");
            });

            mediaRecorder.start();

            // Update UI to indicate that recording is in progress
            appendMessage(PERSON_NAME, PERSON_IMG, "right", "Speaking...");
            isRecording = true;
            micBtn.textContent = "Stop";
            micBtn.classList.add("recording");
          })
          .catch((error) => {
            console.error("Failed to access microphone:", error);
          });
      } else {
        mediaRecorder.stop();
      }
    });

    // For debugging purposes
    function downloadWebm(blob) {
      const url = URL.createObjectURL(blob);
      const downloadLink = document.createElement("a");
      downloadLink.href = url;
      downloadLink.download = "recorded_audio.webm";
      document.body.appendChild(downloadLink);
      downloadLink.click();
      document.body.removeChild(downloadLink);
      URL.revokeObjectURL(url);
    }

    function appendMessage(name, img, side, text) {
      const msgHTML = `
      <div class="msg ${side}-msg">
        <div class="msg-img" style="background-image: url(${img})"></div>

        <div class="msg-bubble">
          <div class="msg-info">
            <div class="msg-info-name">${name}</div>
            <div class="msg-info-time">${formatDate(new Date())}</div>
          </div>

          <div class="msg-text">${text}</div>
        </div>
      </div>
      `;

      msgerChat.insertAdjacentHTML("beforeend", msgHTML);
      msgerChat.scrollTop += 1000;
    }

    function botResponseAudioInput(blob) {
      const formData = new FormData();
      formData.append("wav", blob, "audio.wav");

      $.ajax({
        type: "POST",
        url: "/whisper",
        data: formData,
        processData: false,
        contentType: false,
        success: function (data) {
          const rightmsgs = msgerChat.querySelectorAll("div.msg.right-msg");
          rightmsgs[rightmsgs.length - 1].querySelector("div.msg-bubble > div.msg-text").innerText = data;
          msgerChat.scrollTop += 1000;
          botResponse(data);
        },
        error: function (error) {
          console.error("Failed to send audio input:", error);
        }
      });
    }

    // Also reveal the texts in a fake-streaming manner as the speech goes
    function textToSpeech(text) {
      return new Promise(async (resolve) => {
        try {
          let formData = new FormData();
          formData.append('text', text);

          const response = await fetch('/synthesize', {
            method: 'POST',
            body: formData,
          });

          const data = await response.json();
          const audioContext = new AudioContext();
          const audioBuffer = await fetch(data.audio_url)
            .then(response => response.arrayBuffer())
            .then(data => audioContext.decodeAudioData(data));
          const audioSource = audioContext.createBufferSource();
          audioSource.buffer = audioBuffer;
          audioSource.connect(audioContext.destination);

          audioSource.addEventListener('ended', () => {
            resolve();
          });

          audioSource.playbackRate = 1.2;
          audioSource.start();
          revealText(text, 50);
        } catch (error) {
          console.error('Error during text-to-speech:', error);
          revealText(text, 50);
          resolve();
        }
      });
    }

    function revealText(text, delay) {
      const leftmsgs = msgerChat.querySelectorAll("div.msg.left-msg");
      const msg_text = leftmsgs[leftmsgs.length - 1].querySelector("div.msg-bubble > div.msg-text");
      msg_text.innerHTML = "";

      const paragraphs = text.split(/\r?\n/);
      let currentIndex = 0;

      const revealNextWord = () => {
        if (currentIndex < paragraphs.length) {
          const paragraph = paragraphs[currentIndex];
          const words = paragraph.split(" ");

          let wordIndex = 0;
          const revealNextWordInParagraph = () => {
            if (wordIndex < words.length) {
              const word = words[wordIndex];
              msg_text.innerHTML += word + " ";
              msgerChat.scrollTop += 100;
              wordIndex++;
              setTimeout(revealNextWordInParagraph, word.length * delay);
            } else {
              msg_text.innerHTML += "<br>";
              currentIndex++;
              setTimeout(revealNextWord, delay * 2);
            }
          };

          revealNextWordInParagraph();
        }
      };
      revealNextWord();
    }

    // Major handlers of the chatbot
    function botResponse(rawText) {
      appendMessage(BOT_NAME, BOT_IMG, "left", "");
      // Update the content to a loading gif
      const leftmsgs = msgerChat.querySelectorAll("div.msg.left-msg");
      leftmsgs[leftmsgs.length - 1].querySelector("div.msg-bubble > div.msg-text").innerHTML = `
        <img src="/static/loading.gif" alt="Loading" width="40" height="40">
      `;

      // Image generation
      if (rawText.toLowerCase().startsWith("show me an image of")) {
        var prompt = rawText.substr(rawText.indexOf("f") + 2);
        $.get("/image", { prompt: prompt }).done(function (data) {
          console.log("image:");
          console.log(prompt);
          console.log(data);
          const imgUrl = data;

          // Update the content to an image fetched from the given url
          const leftmsgs = msgerChat.querySelectorAll("div.msg.left-msg");
          leftmsgs[leftmsgs.length - 1].querySelector("div.msg-bubble > div.msg-text").innerHTML = `
            <img src="${imgUrl}" alt="Sorry, we encountered an error." style="max-width: 100%; max-height: 100%;">
          `;
        });
        return;
      }

      // Reddit monitoring
      if (rawText.includes("reddit.com")) {
        $.get("/monitor", { thread_url: rawText }).done(function (data) {
          const res = data;

          const leftmsgs = msgerChat.querySelectorAll("div.msg.left-msg");
          leftmsgs[leftmsgs.length - 1].querySelector("div.msg-bubble > div.msg-text").innerText = res;
        });
        return;
      }

      // Chatbot Response - still take the buffered approach as text-to-speech requires the full text anyway
      $.get("/chat", { msg: rawText }).done(function (data) {
        const msgText = data;
        textToSpeech(msgText);
      });

      // fetch('/chat_stream?msg=' + encodeURIComponent(rawText), { method: 'GET' })
      //   .then(response => {
      //     const reader = response.body.getReader();
      //     let accumulatedText = '';

      //     const readStream = () => {
      //       return reader.read()
      //         .then(async ({ done, value }) => {
      //           if (done) {
      //             console.log('Response streaming complete');
      //             await textToSpeech(accumulatedText);

      //             return;
      //           }
      //           // Process the chunk of data received
      //           const chunk = new TextDecoder('utf-8').decode(value);
      //           accumulatedText += chunk;

      //           // Append the chunk to the chat bubble
      //           const leftmsgs = msgerChat.querySelectorAll("div.msg.left-msg");
      //           leftmsgs[leftmsgs.length - 1].querySelector("div.msg-bubble > div.msg-text").innerText += chunk;

      //           // Dirty hack to intentially slow down the stream
      //           return delay(chunk.length * 20)
      //             .then(() => {
      //               msgerChat.scrollTop += 100;
      //               return readStream();
      //             });
      //         });
      //     };
      //     // Start reading the response stream
      //     return readStream();
      //   })
      //   .catch(error => {
      //     console.error('Error during chat_stream:', error);
      //   });
    }

    // Utils
    function get(selector, root = document) {
      return root.querySelector(selector);
    }

    function formatDate(date) {
      const h = "0" + date.getHours();
      const m = "0" + date.getMinutes();

      return `${h.slice(-2)}:${m.slice(-2)}`;
    }

  </script>

</body>

</html>